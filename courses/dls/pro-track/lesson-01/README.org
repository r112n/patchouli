#-*- mode: org -*-
#+TITLE: Lesson 1
#+STARTUP: latexpreview 

*Attention*: читать данный файл стоит локально на компьютере,
поскольку github плохо отображает формулы...

* Типы задач машинного обучения
- Unsupervised learning (Обучение без учителя)
- Reinforcement learning (Обучение с подкреплением)
- Supervised learning (Обучение с учителем)

** Unsupervised learning
Пример задачи:
#+BEGIN_QUOTE
Кластеризация. Разделение аудитории на группы с общими интересами для
эффективной рекламы
#+END_QUOTE

** Reinforcement learning
Основан на том, что алгоритм за каждое свое действие получает награду
или наказание.
Пример: AlphaGo

* Обучение с учителем

$X$ - множество объектов

$ Y $- множество ответов

$y: X \rightarrow Y$ - истинная зависимость

Обучающий датасет - множество наборов из фичей и значений целевой
переменной.
Мы обозначим его $X_{\text{train}} \subset X$.

$$
X = \begin{pmatrix}
x_{11} & x_{12} & ... & x_{1m} \\
       &  ...   & ... &        \\
x_{n1} & x_{n2} & ... & x_{nm}
\end{pmatrix}
$$


$$
Y_{\text{train}} = \begin{pmatrix}
y_1 \\
... \\
y_n
\end{pmatrix}
$$

"Учитель" означает, что у нас есть набор объектов для которых ответ
известен (в отличии от unsupervised learning).

$x_{ij}$ - признак

** Типы признаков (features):
- Числовые (Numerical)

- Категориальные (Categorical)
  Обычно нужно придумать их числовое представление.
  
- Порядковые (Ordinal)

** Типы задач:
- Классификация (Classification)

  $Y = \{0, 1\}, Y = \{1, 2, ..., n\}, Y = \{0, 1\}^n$

- Регрессия (Regression)

  $Y = \mathbb{R}$

- Ранжирование (Ranking)
  
  $Y = \{1, 2, ..., n\}$

  (числа упорядочены)

** Примеры задач
*** Ирисы Фишера
*Какая это задача?*
Есть три вида ириса: setosa, versicolor, virginica.

$$ Y = \{1, 2, 3\} $$

Задача классификации

*Какие есть признаки?*
У них есть 4 параметра: Sepal.Length, Sepal.Width, Petal.Length,
Petal.Width

$$ X = \mathbb{R}^4 $$

Все признаки числовые.

*** Цена дома
Нужно предсказать стоимость дома. Есть датасет со следующими
признаками:
- Удаленность от метро
- Оценка состояния дома(плохое, среднее, хорошее, отличное)
- Колличество комнат
- Площадь
- Год строительства
- Название района, в котором находится дом

*Какая это задача?*

$$ Y = \mathbb{R} $$

Задача регрессии.

*Какие есть признаки?*

Числовые, порядковые, категориальные.

*** Поисковая выдача
Получив запрос от пользователя нужно найти наиболее полезные документы
из некоторой базы.

Что нам известно:
- Запрос пользователя
- Текст документа
- Какие ключевые слова есть в каждом документе.
- Насколько каждый документ популярен
- итд

*Какая это задача?*

$ Y = \{1, 2, ..., n\} $ (числа упорядочены)

Задача ранжирования.

*Какие есть признаки?*

Все сложно, здесь нужно думать...

* K-Nearest Neighbors
*Решение задачи классификации*:
/Обучение/: Запоминание обучающей выборки
/Предсказание/:
- Получаем точку *x*, в которой надо сделать предсказание
- Ищем k ближайших соседей
- В качестве ответа возвращаем класс, которого больше всего среди
  соседей.

На самом деле решать задачу классификации здесь решать сложнее, чем
задачу регрессии, поскольку в области может оказаться равное
колличество соседей с одинаковым классом.

** Curse of Dimensionality
В KNN мы делаем предположение: близкие точки будут иметь близкие
ответы.
При увеличении размерности данных(увеличении колличества признаков) в
близкую область будет попадать мало объектов.

** Feature Scale
Если в качестве метрики взять обычное расстояние между векторами, то
возникает проблема масштаба признаков.

*** Пример
Задача определения стоимости дома по признакам:
- Расстояние до метро в метрах
- Количество комнат

Колличество комнат почти не будет влиять на предсказание

* Обучение моделей

** Пример семейства моделей (функций порога)
*Задача*: определить, можно ли ребенку пройти на аттракцион? Причем мы
 знаем его рост и возраст.

 Множество, в котором мы будем искать решения состоит из функций вида:
 
 $$
 \hat{y}_{(a, b)}(x_1, x_2) = \begin{cases}
 1 & x_1 \geq a, x_2 \geq b \\
 0 & \text{otherwise}
 \end{cases}
 $$

 Параметр в данном случае $\theta = (a, b)$. А множество возможных
 значений параметра $\theta = \mathbb{R}^2$.

** Supervised learning
*Обучение* -- процесс выбора параметра $\theta$, которому
соответствует наиболее подходящее нам решение задачи
$\hat{y}_{\theta}(x_1, x_2)$.

_Как обучать алгоритм(подбирать оптимальные параметры)?_

*Функция потерь (loss)*:
Определим функцию $L(y,\hat{y}(x))$, ее значение показывает насколько
сильно наше предсказание отличается от реального значения.

*Пример*:
Задача предсказания цены дома из предыдущих примеров.

Возможные функции потерь:

$L(y_{\text{true}},\hat{y}(x)) = (y_{\text{true}} - \hat{y}(x))^2$ --
квадратичная функция потерь

$L(y_{\text{true}},\hat{y}(x)) = |y_{\text{true}} - \hat{y}(x)|$ --
aбсолютная функция потерь

$L(y_{\text{true}},\hat{y}(x)) = (y_{\text{true}} - \hat{y}(x))^2 + 7$

*** Эмпирический риск
Определим эмпирический риск как среднее значение функции потерь на
обучающем датасете.
Часто функцию эмпирического риска также называются лоссом.

Смотри определение из мат. стата :)


* Линейная регрессия и переобучение
Вспомним как выглядит линейная регрессия:

$$
\hat{y}(x_1, x_2, ..., x_n) = \theta_0 + \theta_1 x_1 + \theta_2 x_2 +
... + \theta_n x_n
$$

*Обучение линейной регрессии*:

Классически в качестве лосса берут Mean Squared Error

$$
\text{argmin}_{\theta_0,...,\theta_n} \sum_{i} (y^i_{\text{true}} -
\theta_0 - \theta_1 x_1^i - ... - \theta_n x_n^i)^2
$$

*Polynomial Regression*:

Пусть у нас изначально есть только один признак $x$. Создадим новые:

$$
x_1 = x, x_2 = x^2, ..., x_n = x^n
$$

Тогда линейная регрессия от таких признаков называется
_полиномиальной_:

$$
\hat{y}(x) = \theta_0 + \theta_1 x + \theta_2 x^2 + ... + \theta_n x^n
$$

** Переобучение для линейной регрессии
Легко заметить, что при увеличении степени при полиномальной линейной
регресии, функция будет лучше описывать данные на тестовом датасете,
однако при выходе из него, зависимость будет сильно нарушаться.

** Переобучение для KNN
Если в KNN мы положим $k=1$, то получим идеальные предсказания на всем
обучающем датасете и средний лосс будет равен нулю.

Однако, такие предсказания могут быть очень плохими

** Как находить переобучение и бороться с ним?

*** Разделение на Train/Validation/Test
- Train - данные для обучения
- Validation - данные для итеративной оценки качества.
- Test - данные для финальной оценки качества.

Часто можно опустить test часть. В этом случае названия validation
dataset и test dataset означают одно и то же.

*** Формальное определение переобучения
*Переобучение* - ситуация, когда качество модели на train значительно
лучше, чем на validation/test.

*** Cross-validation
Пусть есть все данные(All data).

Разделим всю нашу тренировочную выборку на 5 частей. Будем перебирать часть которая
будет являться тестовой. Обучаемся на каждой вариации. Итоговую
проверку качества делаем на тестовой выборке. 

* Алгоритм применения ML к задачам

- Разделяем датасет на части: train, validation, test.
- Обрабатываем данные
- Пока качество на validation не достаточно высокое
  - Выбераем модель и гиперпараметры
  - Обучаем
  - Проверяем качество на validation сете
- Проверяем качество на test сете
